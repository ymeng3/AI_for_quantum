{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinmeng/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/justinmeng/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'htr.bmp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 85\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: label,\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms_htr_pixel\u001b[39m\u001b[38;5;124m\"\u001b[39m: s_htr_pix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms_rt13_combined\u001b[39m\u001b[38;5;124m\"\u001b[39m: s_rt13\n\u001b[1;32m     80\u001b[0m     }\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Example run (Colab)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtr.bmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrt13.bmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.bmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[2], line 51\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(htr_path, rt13_path, test_path, alpha)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(htr_path, rt13_path, test_path, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Pixel features\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     x_htr_pix \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_pixel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtr_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     x_rt13_pix \u001b[38;5;241m=\u001b[39m preprocess_pixel(rt13_path)\n\u001b[1;32m     53\u001b[0m     x_test_pix \u001b[38;5;241m=\u001b[39m preprocess_pixel(test_path)\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mpreprocess_pixel\u001b[0;34m(path, size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_pixel\u001b[39m(path, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess for pixel-level similarity: grayscale, resize, normalize.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(size)\n\u001b[1;32m     18\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/PIL/Image.py:3513\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[1;32m   3512\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[0;32m-> 3513\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3514\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'htr.bmp'"
     ]
    }
   ],
   "source": [
    "## Original Version by Ziyu \n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# -----------------------\n",
    "# Preprocessing functions\n",
    "# -----------------------\n",
    "\n",
    "def preprocess_pixel(path, size=(224, 224)):\n",
    "    \"\"\"Preprocess for pixel-level similarity: grayscale, resize, normalize.\"\"\"\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize(size)\n",
    "    arr = np.array(img, dtype=np.float32)\n",
    "    arr = (arr - arr.mean()) / (arr.std() + 1e-6)  # normalize\n",
    "    return arr.flatten()[None, :]  # shape (1, D)\n",
    "\n",
    "# Pretrained CNN (ResNet-18 for simplicity)\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # remove final classifier, keep features\n",
    "resnet.eval()\n",
    "\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def preprocess_cnn(path):\n",
    "    \"\"\"Preprocess for CNN features: resize, 3 channels, normalize for ResNet.\"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0)  # shape (1,3,224,224)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).numpy()\n",
    "    return feat  # shape (1, D)\n",
    "\n",
    "# -----------------------\n",
    "# Similarity + Prediction\n",
    "# -----------------------\n",
    "\n",
    "def cosine(a, b):\n",
    "    return cosine_similarity(a, b)[0, 0]\n",
    "\n",
    "def predict(htr_path, rt13_path, test_path, alpha=0.5):\n",
    "    # Pixel features\n",
    "    x_htr_pix = preprocess_pixel(htr_path)\n",
    "    x_rt13_pix = preprocess_pixel(rt13_path)\n",
    "    x_test_pix = preprocess_pixel(test_path)\n",
    "\n",
    "    s_htr_pix = cosine(x_test_pix, x_htr_pix)\n",
    "    s_rt13_pix = cosine(x_test_pix, x_rt13_pix)\n",
    "\n",
    "    # CNN features\n",
    "    x_htr_cnn = preprocess_cnn(htr_path)\n",
    "    x_rt13_cnn = preprocess_cnn(rt13_path)\n",
    "    x_test_cnn = preprocess_cnn(test_path)\n",
    "\n",
    "    s_htr_cnn = cosine(x_test_cnn, x_htr_cnn)\n",
    "    s_rt13_cnn = cosine(x_test_cnn, x_rt13_cnn)\n",
    "\n",
    "    # Combined similarity\n",
    "    s_htr = alpha * s_htr_cnn + (1 - alpha) * s_htr_pix\n",
    "    s_rt13 = alpha * s_rt13_cnn + (1 - alpha) * s_rt13_pix\n",
    "\n",
    "    label = \"htr\" if s_htr > s_rt13 else \"rt13\"\n",
    "\n",
    "    return {\n",
    "        \"prediction\": label,\n",
    "        \"s_htr_pixel\": s_htr_pix,\n",
    "        \"s_rt13_pixel\": s_rt13_pix,\n",
    "        \"s_htr_cnn\": s_htr_cnn,\n",
    "        \"s_rt13_cnn\": s_rt13_cnn,\n",
    "        \"s_htr_combined\": s_htr,\n",
    "        \"s_rt13_combined\": s_rt13\n",
    "    }\n",
    "\n",
    "# -----------------------\n",
    "# Example run (Colab)\n",
    "# -----------------------\n",
    "result = predict(\"htr.bmp\", \"rt13.bmp\", \"test.bmp\", alpha=0.5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinmeng/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/justinmeng/.pyenv/versions/3.9.19/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'htr.bmp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 85\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: label,\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms_htr_pixel\u001b[39m\u001b[38;5;124m\"\u001b[39m: s_htr_pix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms_rt13_combined\u001b[39m\u001b[38;5;124m\"\u001b[39m: s_rt13\n\u001b[1;32m     80\u001b[0m     }\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Example run (Colab)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtr.bmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrt13.bmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.bmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(htr_path, rt13_path, test_path, alpha)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(htr_path, rt13_path, test_path, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Pixel features\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     x_htr_pix \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_pixel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtr_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     x_rt13_pix \u001b[38;5;241m=\u001b[39m preprocess_pixel(rt13_path)\n\u001b[1;32m     53\u001b[0m     x_test_pix \u001b[38;5;241m=\u001b[39m preprocess_pixel(test_path)\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mpreprocess_pixel\u001b[0;34m(path, size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_pixel\u001b[39m(path, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess for pixel-level similarity: grayscale, resize, normalize.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(size)\n\u001b[1;32m     18\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.19/lib/python3.9/site-packages/PIL/Image.py:3513\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[1;32m   3512\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[0;32m-> 3513\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3514\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'htr.bmp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# -----------------------\n",
    "# Preprocessing functions\n",
    "# -----------------------\n",
    "\n",
    "def preprocess_pixel(path, size=(224, 224)):\n",
    "    \"\"\"Preprocess for pixel-level similarity: grayscale, resize, normalize.\"\"\"\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize(size)\n",
    "    arr = np.array(img, dtype=np.float32)\n",
    "    arr = (arr - arr.mean()) / (arr.std() + 1e-6)  # normalize\n",
    "    return arr.flatten()[None, :]  # shape (1, D)\n",
    "\n",
    "# Pretrained CNN (ResNet-18 for simplicity)\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # remove final classifier, keep features\n",
    "resnet.eval()\n",
    "\n",
    "transform_cnn = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def preprocess_cnn(path):\n",
    "    \"\"\"Preprocess for CNN features: resize, 3 channels, normalize for ResNet.\"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    x = transform_cnn(img).unsqueeze(0)  # shape (1,3,224,224)\n",
    "    with torch.no_grad():\n",
    "        feat = resnet(x).numpy()\n",
    "    return feat  # shape (1, D)\n",
    "\n",
    "# -----------------------\n",
    "# Similarity + Prediction\n",
    "# -----------------------\n",
    "\n",
    "def cosine(a, b):\n",
    "    return cosine_similarity(a, b)[0, 0]\n",
    "\n",
    "def predict(htr_path, rt13_path, test_path, alpha=0.5):\n",
    "    # Pixel features\n",
    "    x_htr_pix = preprocess_pixel(htr_path)\n",
    "    x_rt13_pix = preprocess_pixel(rt13_path)\n",
    "    x_test_pix = preprocess_pixel(test_path)\n",
    "\n",
    "    s_htr_pix = cosine(x_test_pix, x_htr_pix)\n",
    "    s_rt13_pix = cosine(x_test_pix, x_rt13_pix)\n",
    "\n",
    "    # CNN features\n",
    "    x_htr_cnn = preprocess_cnn(htr_path)\n",
    "    x_rt13_cnn = preprocess_cnn(rt13_path)\n",
    "    x_test_cnn = preprocess_cnn(test_path)\n",
    "\n",
    "    s_htr_cnn = cosine(x_test_cnn, x_htr_cnn)\n",
    "    s_rt13_cnn = cosine(x_test_cnn, x_rt13_cnn)\n",
    "\n",
    "    # Combined similarity\n",
    "    s_htr = alpha * s_htr_cnn + (1 - alpha) * s_htr_pix\n",
    "    s_rt13 = alpha * s_rt13_cnn + (1 - alpha) * s_rt13_pix\n",
    "\n",
    "    label = \"htr\" if s_htr > s_rt13 else \"rt13\"\n",
    "\n",
    "    return {\n",
    "        \"prediction\": label,\n",
    "        \"s_htr_pixel\": s_htr_pix,\n",
    "        \"s_rt13_pixel\": s_rt13_pix,\n",
    "        \"s_htr_cnn\": s_htr_cnn,\n",
    "        \"s_rt13_cnn\": s_rt13_cnn,\n",
    "        \"s_htr_combined\": s_htr,\n",
    "        \"s_rt13_combined\": s_rt13\n",
    "    }\n",
    "\n",
    "# -----------------------\n",
    "# Example run (Colab)\n",
    "# -----------------------\n",
    "result = predict(\"htr.bmp\", \"rt13.bmp\", \"test.bmp\", alpha=0.5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] bank saved -> artifacts/banks/sto_bank_2025_10_20.npz\n",
      "     tau_margin=0.020, kappa_minsim=0.150, temperature=0.50\n",
      "     rt13 exemplars: 8, htr exemplars: 10\n",
      "[OK] wrote 4 predictions -> artifacts/results/test_preds.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'file': 'HTR_12.png',\n",
       "  'label': 'uncertain',\n",
       "  's_rt13': 0.963294678674919,\n",
       "  's_htr': 0.9825009697241804,\n",
       "  's_max': 0.9825009697241804,\n",
       "  'margin': 0.019206291049261415,\n",
       "  'p_rt13': 0.4903980351088602,\n",
       "  'p_htr': 0.5096019648906301,\n",
       "  'w_rt13': 0.0,\n",
       "  'w_htr': 1.0},\n",
       " {'file': 'HTR_13.png',\n",
       "  'label': 'htr',\n",
       "  's_rt13': 0.9593800400781332,\n",
       "  's_htr': 0.9826346059437672,\n",
       "  's_max': 0.9826346059437672,\n",
       "  'margin': 0.023254565865634014,\n",
       "  'p_rt13': 0.488374812527663,\n",
       "  'p_htr': 0.5116251874718253,\n",
       "  'w_rt13': 0.0,\n",
       "  'w_htr': 1.0},\n",
       " {'file': 'RT13_11.png',\n",
       "  'label': 'uncertain',\n",
       "  's_rt13': 0.9861658445474778,\n",
       "  's_htr': 0.981800948384859,\n",
       "  's_max': 0.9861658445474778,\n",
       "  'margin': 0.004364896162618814,\n",
       "  'p_rt13': 0.5021824342209308,\n",
       "  'p_htr': 0.49781756577856695,\n",
       "  'w_rt13': 0.7087100914341642,\n",
       "  'w_htr': 0.29128990856583586},\n",
       " {'file': 'RT13_8.png',\n",
       "  'label': 'uncertain',\n",
       "  's_rt13': 0.9751316476790102,\n",
       "  's_htr': 0.9615956929753822,\n",
       "  's_max': 0.9751316476790102,\n",
       "  'margin': 0.013535954703628006,\n",
       "  'p_rt13': 0.5067675640342426,\n",
       "  'p_htr': 0.4932324359652506,\n",
       "  'w_rt13': 1.0,\n",
       "  'w_htr': 0.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STO RHEED classifier (HTR vs √13) — Notebook-friendly version\n",
    "# - ResNet-18 grayscale→3ch embeddings + FFT radial profile\n",
    "# - Center-disk masking\n",
    "# - Prototype bank + thresholds (τ margin, κ min-sim)\n",
    "# - Tune on Val if provided; else leave-one-out (LOO)\n",
    "# - Functions can be called directly in a notebook\n",
    "# - Optional CLI if executed as a script\n",
    "\n",
    "import os, glob, json, math, csv, argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.optimize import nnls\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ---------------------------\n",
    "# Device & model (global)\n",
    "# ---------------------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def _init_resnet18():\n",
    "    resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    resnet.fc = nn.Identity()\n",
    "    resnet.to(DEVICE).eval()\n",
    "    return resnet\n",
    "\n",
    "RESNET = _init_resnet18()\n",
    "\n",
    "# Grayscale → 3ch + simple gray stats (domain-robust)\n",
    "TRANS_GRAY3 = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.Grayscale(num_output_channels=3),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities & preprocessing\n",
    "# ---------------------------\n",
    "def l2norm(x: np.ndarray, axis=1, eps=1e-12):\n",
    "    return x / (np.linalg.norm(x, axis=axis, keepdims=True) + eps)\n",
    "\n",
    "def list_images(folder: Optional[str]) -> List[str]:\n",
    "    if not folder:\n",
    "        return []\n",
    "    exts = (\"*.png\", \"*.bmp\", \"*.jpg\", \"*.jpeg\", \"*.tif\", \"*.tiff\")\n",
    "    paths: List[str] = []\n",
    "    for e in exts:\n",
    "        paths += glob.glob(os.path.join(folder, e))\n",
    "    return sorted(paths)\n",
    "\n",
    "def imread_gray(path: str) -> np.ndarray:\n",
    "    return np.array(Image.open(path).convert('L'), dtype=np.float32)\n",
    "\n",
    "def apply_center_mask(gray: np.ndarray, frac: float = 0.60) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Mask out the central bright disk; keep annulus.\n",
    "    frac is the fraction of the shorter side used as mask diameter.\n",
    "    \"\"\"\n",
    "    h, w = gray.shape\n",
    "    cy, cx = h / 2.0, w / 2.0\n",
    "    R = min(h, w) * frac * 0.5  # radius\n",
    "    yy, xx = np.ogrid[:h, :w]\n",
    "    mask = ((yy - cy) ** 2 + (xx - cx) ** 2) > R ** 2\n",
    "    out = gray.copy()\n",
    "    out[~mask] = np.median(gray)\n",
    "    return out\n",
    "\n",
    "def fft_radial_profile(gray_224: np.ndarray, n_bins: int = 128) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalized radial power spectrum (1, n_bins).\n",
    "    gray_224 should already be 224x224 for consistency.\n",
    "    \"\"\"\n",
    "    g = (gray_224 - gray_224.mean()) / (gray_224.std() + 1e-6)\n",
    "    F = np.fft.fftshift(np.fft.fft2(g))\n",
    "    P = np.abs(F) ** 2\n",
    "    h, w = P.shape\n",
    "    cy, cx = h / 2.0, w / 2.0\n",
    "    yy, xx = np.indices(P.shape)\n",
    "    r = np.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
    "    r_norm = r / r.max()\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    idx = np.digitize(r_norm.ravel(), bins) - 1\n",
    "    prof = np.array([P.ravel()[idx == i].mean() if np.any(idx == i) else 0.0 for i in range(n_bins)])\n",
    "    prof = prof / (prof.max() + 1e-12)\n",
    "    return prof[None, :]\n",
    "\n",
    "def resnet_features_from_path(path: str) -> np.ndarray:\n",
    "    img = Image.open(path)\n",
    "    x = TRANS_GRAY3(img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        feat = RESNET(x)  # (1, D)\n",
    "    f = feat.cpu().numpy()\n",
    "    return l2norm(f, axis=1)\n",
    "\n",
    "def extract_features(path: str, mask_center: bool = True, fft_bins: int = 128) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Unified feature: [ResNet_embed || FFT_radial_profile], L2-normalized.\n",
    "    \"\"\"\n",
    "    # CNN embed (grayscale→3ch)\n",
    "    f_cnn = resnet_features_from_path(path)  # (1, D1)\n",
    "\n",
    "    # FFT radial on masked grayscale resized to 224\n",
    "    gray = imread_gray(path)\n",
    "    if mask_center:\n",
    "        gray = apply_center_mask(gray)\n",
    "    gray224 = np.array(Image.fromarray(gray).resize((224, 224)))\n",
    "    f_fft = fft_radial_profile(gray224, n_bins=fft_bins)  # (1, 128)\n",
    "\n",
    "    f = np.concatenate([f_cnn, f_fft], axis=1)\n",
    "    return l2norm(f, axis=1)\n",
    "\n",
    "# ---------------------------\n",
    "# Bank data classes\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class BankMeta:\n",
    "    fft_bins: int\n",
    "    mask_center: bool\n",
    "    feature_dim: int\n",
    "    tau_margin: float\n",
    "    kappa_minsim: float\n",
    "    temperature: float\n",
    "    rt13_files: List[str]\n",
    "    htr_files: List[str]\n",
    "\n",
    "@dataclass\n",
    "class PrototypeBank:\n",
    "    mu_rt13: np.ndarray     # (D,)\n",
    "    mu_htr:  np.ndarray     # (D,)\n",
    "    E_rt13:  np.ndarray     # (N_rt13, D)\n",
    "    E_htr:   np.ndarray     # (N_htr, D)\n",
    "    meta:    BankMeta\n",
    "\n",
    "    def save(self, out_npz: str):\n",
    "        os.makedirs(os.path.dirname(out_npz), exist_ok=True) if os.path.dirname(out_npz) else None\n",
    "        np.savez_compressed(\n",
    "            out_npz,\n",
    "            mu_rt13=self.mu_rt13,\n",
    "            mu_htr=self.mu_htr,\n",
    "            E_rt13=self.E_rt13,\n",
    "            E_htr=self.E_htr,\n",
    "            meta=json.dumps(asdict(self.meta))\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path_npz: str) -> \"PrototypeBank\":\n",
    "        z = np.load(path_npz, allow_pickle=True)\n",
    "        meta = BankMeta(**json.loads(str(z[\"meta\"])))\n",
    "        return PrototypeBank(\n",
    "            mu_rt13=z[\"mu_rt13\"],\n",
    "            mu_htr=z[\"mu_htr\"],\n",
    "            E_rt13=z[\"E_rt13\"],\n",
    "            E_htr=z[\"E_htr\"],\n",
    "            meta=meta\n",
    "        )\n",
    "\n",
    "# ---------------------------\n",
    "# Threshold tuning (Val or LOO)\n",
    "# ---------------------------\n",
    "def _grid_f1_tau_kappa(sim_pairs: List[Tuple[float, float, int]]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    sim_pairs: list of (s_rt13, s_htr, y_true) with y_true in {1 (rt13), 0 (htr)}.\n",
    "    Returns best (tau, kappa) by macro-F1, counting abstain as wrong.\n",
    "    \"\"\"\n",
    "    taus   = np.linspace(0.02, 0.15, 8)\n",
    "    kappas = np.linspace(0.15, 0.35, 9)\n",
    "    best_f1, best = -1.0, (0.08, 0.25)\n",
    "    y_true = [y for _, _, y in sim_pairs]\n",
    "    for t in taus:\n",
    "        for k in kappas:\n",
    "            y_pred = []\n",
    "            for sr, sh, _ in sim_pairs:\n",
    "                smax = max(sr, sh); margin = abs(sr - sh)\n",
    "                if smax < k or margin < t:\n",
    "                    y_pred.append(-1)  # abstain → treat as wrong for tuning\n",
    "                else:\n",
    "                    y_pred.append(1 if sr > sh else 0)\n",
    "            tp = sum((yt==1 and yp==1) for yt, yp in zip(y_true, y_pred))\n",
    "            tn = sum((yt==0 and yp==0) for yt, yp in zip(y_true, y_pred))\n",
    "            fp = sum((yt==0 and yp==1) for yt, yp in zip(y_true, y_pred))\n",
    "            fn = sum((yt==1 and yp==0) for yt, yp in zip(y_true, y_pred))\n",
    "            prec_pos = tp / max(1, tp+fp);  rec_pos = tp / max(1, tp+fn)\n",
    "            prec_neg = tn / max(1, tn+fn);  rec_neg = tn / max(1, tn+fp)\n",
    "            f1_pos = 2*prec_pos*rec_pos / max(1e-12, (prec_pos+rec_pos))\n",
    "            f1_neg = 2*prec_neg*rec_neg / max(1e-12, (prec_neg+rec_neg))\n",
    "            f1_macro = 0.5 * (f1_pos + f1_neg)\n",
    "            if f1_macro > best_f1:\n",
    "                best_f1, best = f1_macro, (t, k)\n",
    "    return best\n",
    "\n",
    "def _tune_thresholds_on_val(mu_rt13: np.ndarray, mu_htr: np.ndarray,\n",
    "                            val_rt13_paths: List[str], val_htr_paths: List[str],\n",
    "                            mask_center=True, fft_bins=128) -> Optional[Tuple[float,float]]:\n",
    "    if not val_rt13_paths or not val_htr_paths:\n",
    "        return None\n",
    "    sims = []\n",
    "    for p in val_rt13_paths:\n",
    "        f = extract_features(p, mask_center=mask_center, fft_bins=fft_bins)\n",
    "        sr = float(cosine_similarity(f, mu_rt13[None, :])[0, 0])\n",
    "        sh = float(cosine_similarity(f, mu_htr [None, :])[0, 0])\n",
    "        sims.append((sr, sh, 1))\n",
    "    for p in val_htr_paths:\n",
    "        f = extract_features(p, mask_center=mask_center, fft_bins=fft_bins)\n",
    "        sr = float(cosine_similarity(f, mu_rt13[None, :])[0, 0])\n",
    "        sh = float(cosine_similarity(f, mu_htr [None, :])[0, 0])\n",
    "        sims.append((sr, sh, 0))\n",
    "    return _grid_f1_tau_kappa(sims)\n",
    "\n",
    "# ---------------------------\n",
    "# Build bank (notebook function)\n",
    "# ---------------------------\n",
    "def build_bank_from_dirs(rt13_dir: str,\n",
    "                         htr_dir: str,\n",
    "                         out_npz: Optional[str] = None,\n",
    "                         fft_bins: int = 128,\n",
    "                         mask_center: bool = True,\n",
    "                         val_rt13_dir: Optional[str] = None,\n",
    "                         val_htr_dir: Optional[str] = None) -> PrototypeBank:\n",
    "    rt13_paths = list_images(rt13_dir)\n",
    "    htr_paths  = list_images(htr_dir)\n",
    "    if not rt13_paths or not htr_paths:\n",
    "        raise FileNotFoundError(\"No exemplar images found in provided exemplar folders.\")\n",
    "\n",
    "    E_rt13 = np.vstack([extract_features(p, mask_center=mask_center, fft_bins=fft_bins)[0] for p in rt13_paths])\n",
    "    E_htr  = np.vstack([extract_features(p, mask_center=mask_center, fft_bins=fft_bins)[0] for p in htr_paths])\n",
    "\n",
    "    mu_rt13 = l2norm(E_rt13.mean(axis=0, keepdims=True), axis=1)[0]\n",
    "    mu_htr  = l2norm(E_htr.mean(axis=0,  keepdims=True), axis=1)[0]\n",
    "\n",
    "    # thresholds: try Val first; fallback to LOO\n",
    "    tau, kappa, temp = 0.08, 0.25, 0.50\n",
    "    tuned = None\n",
    "    val_rt13_paths = list_images(val_rt13_dir)\n",
    "    val_htr_paths  = list_images(val_htr_dir)\n",
    "    if val_rt13_paths and val_htr_paths:\n",
    "        tuned = _tune_thresholds_on_val(mu_rt13, mu_htr, val_rt13_paths, val_htr_paths,\n",
    "                                        mask_center=mask_center, fft_bins=fft_bins)\n",
    "    if tuned is None:\n",
    "        # LOO on exemplars\n",
    "        sims = []\n",
    "        all_pairs = [(p, 1) for p in rt13_paths] + [(p, 0) for p in htr_paths]\n",
    "        for p, y in all_pairs:\n",
    "            f = extract_features(p, mask_center=mask_center, fft_bins=fft_bins)\n",
    "            sr = float(cosine_similarity(f, mu_rt13[None, :])[0, 0])\n",
    "            sh = float(cosine_similarity(f, mu_htr [None, :])[0, 0])\n",
    "            sims.append((sr, sh, y))\n",
    "        tau, kappa = _grid_f1_tau_kappa(sims)\n",
    "    else:\n",
    "        tau, kappa = tuned\n",
    "\n",
    "    meta = BankMeta(\n",
    "        fft_bins=fft_bins,\n",
    "        mask_center=mask_center,\n",
    "        feature_dim=int(len(mu_rt13)),\n",
    "        tau_margin=float(tau),\n",
    "        kappa_minsim=float(kappa),\n",
    "        temperature=0.50,\n",
    "        rt13_files=rt13_paths,\n",
    "        htr_files=htr_paths,\n",
    "    )\n",
    "    bank = PrototypeBank(mu_rt13=mu_rt13, mu_htr=mu_htr, E_rt13=E_rt13, E_htr=E_htr, meta=meta)\n",
    "\n",
    "    if out_npz:\n",
    "        bank.save(out_npz)\n",
    "        print(f\"[OK] bank saved -> {out_npz}\")\n",
    "        print(f\"     tau_margin={bank.meta.tau_margin:.3f}, kappa_minsim={bank.meta.kappa_minsim:.3f}, temperature={bank.meta.temperature:.2f}\")\n",
    "        print(f\"     rt13 exemplars: {len(bank.meta.rt13_files)}, htr exemplars: {len(bank.meta.htr_files)}\")\n",
    "    else:\n",
    "        print(f\"[OK] bank built (not saved). tau={tau:.3f}, kappa={kappa:.3f}\")\n",
    "    return bank\n",
    "\n",
    "# ---------------------------\n",
    "# Prediction helpers\n",
    "# ---------------------------\n",
    "def softmax_scores(scores: np.ndarray, T: float = 1.0) -> np.ndarray:\n",
    "    z = (scores / max(1e-12, T))\n",
    "    z = z - z.max()\n",
    "    e = np.exp(z)\n",
    "    return e / (e.sum() + 1e-12)\n",
    "\n",
    "def mixture_weights_nnls(f: np.ndarray, protos: List[np.ndarray]) -> np.ndarray:\n",
    "    P = np.stack(protos, axis=1)  # (D, C)\n",
    "    w, _ = nnls(P, f)             # (C,)\n",
    "    s = w.sum()\n",
    "    return (w / s) if s > 1e-12 else np.ones_like(w)/len(w)\n",
    "\n",
    "def predict_one(image_path: str, bank: PrototypeBank) -> Dict:\n",
    "    f = extract_features(image_path, mask_center=bank.meta.mask_center, fft_bins=bank.meta.fft_bins)\n",
    "    s_rt13 = float(cosine_similarity(f, bank.mu_rt13[None, :])[0, 0])\n",
    "    s_htr  = float(cosine_similarity(f, bank.mu_htr [None, :])[0, 0])\n",
    "    s_max  = max(s_rt13, s_htr)\n",
    "    margin = abs(s_rt13 - s_htr)\n",
    "\n",
    "    probs = softmax_scores(np.array([s_rt13, s_htr]), T=bank.meta.temperature)\n",
    "    p_rt13, p_htr = float(probs[0]), float(probs[1])\n",
    "\n",
    "    if s_max < bank.meta.kappa_minsim or margin < bank.meta.tau_margin:\n",
    "        label = \"uncertain\"\n",
    "    else:\n",
    "        label = \"rt13\" if s_rt13 > s_htr else \"htr\"\n",
    "\n",
    "    w = mixture_weights_nnls(f[0], [bank.mu_rt13, bank.mu_htr])\n",
    "\n",
    "    return {\n",
    "        \"file\": os.path.basename(image_path),\n",
    "        \"label\": label,\n",
    "        \"s_rt13\": s_rt13,\n",
    "        \"s_htr\":  s_htr,\n",
    "        \"s_max\":  s_max,\n",
    "        \"margin\": margin,\n",
    "        \"p_rt13\": p_rt13,\n",
    "        \"p_htr\":  p_htr,\n",
    "        \"w_rt13\": float(w[0]),\n",
    "        \"w_htr\":  float(w[1]),\n",
    "    }\n",
    "\n",
    "def predict_folder_with_bank(input_dir: str, bank: PrototypeBank, out_csv: Optional[str] = None) -> List[Dict]:\n",
    "    paths = list_images(input_dir)\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images found in '{input_dir}'\")\n",
    "    rows = [predict_one(p, bank) for p in paths]\n",
    "    if out_csv:\n",
    "        os.makedirs(os.path.dirname(out_csv), exist_ok=True) if os.path.dirname(out_csv) else None\n",
    "        with open(out_csv, \"w\", newline=\"\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "            w.writeheader()\n",
    "            for r in rows:\n",
    "                w.writerow(r)\n",
    "        print(f\"[OK] wrote {len(rows)} predictions -> {out_csv}\")\n",
    "    return rows\n",
    "\n",
    "# ---------------------------\n",
    "# Optional CLI (still works if run as a script)\n",
    "# ---------------------------\n",
    "def _cli():\n",
    "    parser = argparse.ArgumentParser(description=\"STO RHEED classifier (HTR vs √13)\")\n",
    "    sub = parser.add_subparsers(dest=\"cmd\", required=True)\n",
    "\n",
    "    p_build = sub.add_parser(\"build-bank\", help=\"Build prototype bank from exemplar folders\")\n",
    "    p_build.add_argument(\"--rt13\", required=True, help=\"Folder of √13 exemplar images\")\n",
    "    p_build.add_argument(\"--htr\",  required=True, help=\"Folder of HTR exemplar images\")\n",
    "    p_build.add_argument(\"--out\",  required=True, help=\"Output .npz path for the bank\")\n",
    "    p_build.add_argument(\"--fft-bins\", type=int, default=128)\n",
    "    p_build.add_argument(\"--no-mask\", action=\"store_true\", help=\"Disable center disk masking\")\n",
    "    # NEW: tune on Val if provided\n",
    "    p_build.add_argument(\"--val-rt13\", default=None, help=\"(optional) Val folder for √13\")\n",
    "    p_build.add_argument(\"--val-htr\",  default=None, help=\"(optional) Val folder for HTR\")\n",
    "\n",
    "    p_pred = sub.add_parser(\"predict\", help=\"Classify images in a folder with a saved bank\")\n",
    "    p_pred.add_argument(\"--bank\", required=True, help=\"Path to bank .npz\")\n",
    "    p_pred.add_argument(\"--in-dir\", required=True, help=\"Folder of images to classify\")\n",
    "    p_pred.add_argument(\"--out-csv\", required=True, help=\"Where to write predictions CSV\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.cmd == \"build-bank\":\n",
    "        bank = build_bank_from_dirs(\n",
    "            rt13_dir=args.rt13,\n",
    "            htr_dir=args.htr,\n",
    "            out_npz=args.out,\n",
    "            fft_bins=args.fft_bins,\n",
    "            mask_center=not args.no_mask,\n",
    "            val_rt13_dir=args.val_rt13,\n",
    "            val_htr_dir=args.val_htr\n",
    "        )\n",
    "        # build_bank_from_dirs already prints thresholds & counts\n",
    "\n",
    "    elif args.cmd == \"predict\":\n",
    "        bank = PrototypeBank.load(args.bank)\n",
    "        predict_folder_with_bank(args.in_dir, bank, args.out_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Running as a script (ignored in notebooks unless you call it)\n",
    "    pass  # replace with: _cli()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bank = build_bank_from_dirs(\n",
    "    htr_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/STO_ideal_HTR\",\n",
    "    rt13_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/STO_ideal_RT13\",\n",
    "    out_npz=\"artifacts/banks/sto_bank_2025_10_20.npz\",  # or None to skip saving\n",
    "    fft_bins=128,\n",
    "    mask_center=True,\n",
    "    val_rt13_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/Val\",   # your Val/ has both classes; that's fine\n",
    "    val_htr_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/Val\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "rows = predict_folder_with_bank(\n",
    "    input_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/Test\",\n",
    "    bank=bank,  # or PrototypeBank.load(\"artifacts/banks/sto_bank_2025_10_20.npz\")\n",
    "    out_csv=\"artifacts/results/test_preds.csv\"\n",
    ")\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] bank saved -> artifacts/banks/sto_bank_2025_10_21.npz\n",
      "τ=0.020, κ=0.150, T=0.30, γ_fft=1.50, k_per_class=2\n",
      "rt13 exemplars used: 21 / 21  |  htr exemplars used: 19 / 19\n",
      "[OK] wrote 7 predictions -> artifacts/results/test_preds.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'file': 'HTR_12.png',\n",
       "  'label': 'htr',\n",
       "  's_rt13': 0.9802926300323045,\n",
       "  's_htr': 0.9893016391323114,\n",
       "  's_max': 0.9893016391323114,\n",
       "  'margin': 0.009009009100006904,\n",
       "  'p_rt13': 0.49249305655643444,\n",
       "  'p_htr': 0.507506943443058,\n",
       "  'w_rt13': 0.0,\n",
       "  'w_htr': 1.0},\n",
       " {'file': 'HTR_13.png',\n",
       "  'label': 'htr',\n",
       "  's_rt13': 0.987136418166538,\n",
       "  's_htr': 0.9898926331153116,\n",
       "  's_max': 0.9898926331153116,\n",
       "  'margin': 0.00275621494877365,\n",
       "  'p_rt13': 0.49770317036498396,\n",
       "  'p_htr': 0.5022968296345136,\n",
       "  'w_rt13': 0.0,\n",
       "  'w_htr': 1.0},\n",
       " {'file': 'HTR_15.png',\n",
       "  'label': 'htr',\n",
       "  's_rt13': 0.9766612586196348,\n",
       "  's_htr': 0.9905737135033581,\n",
       "  's_max': 0.9905737135033581,\n",
       "  'margin': 0.01391245488372328,\n",
       "  'p_rt13': 0.48840836496214934,\n",
       "  'p_htr': 0.5115916350373391,\n",
       "  'w_rt13': 0.1740591242334013,\n",
       "  'w_htr': 0.8259408757665988},\n",
       " {'file': 'HTR_16.png',\n",
       "  'label': 'htr',\n",
       "  's_rt13': 0.9716627310517841,\n",
       "  's_htr': 0.9803179406812714,\n",
       "  's_max': 0.9803179406812714,\n",
       "  'margin': 0.008655209629487293,\n",
       "  'p_rt13': 0.4927878255637246,\n",
       "  'p_htr': 0.5072121744357682,\n",
       "  'w_rt13': 0.38477497818059403,\n",
       "  'w_htr': 0.615225021819406},\n",
       " {'file': 'RT13_11.png',\n",
       "  'label': 'htr',\n",
       "  's_rt13': 0.9803693258328577,\n",
       "  's_htr': 0.9889944792971275,\n",
       "  's_max': 0.9889944792971275,\n",
       "  'margin': 0.00862515346426973,\n",
       "  'p_rt13': 0.49281286717486167,\n",
       "  'p_htr': 0.507187132824631,\n",
       "  'w_rt13': 0.0,\n",
       "  'w_htr': 1.0},\n",
       " {'file': 'RT13_12.png',\n",
       "  'label': 'rt13',\n",
       "  's_rt13': 0.9856883658276083,\n",
       "  's_htr': 0.9705911080075913,\n",
       "  's_max': 0.9856883658276083,\n",
       "  'margin': 0.01509725782001703,\n",
       "  'p_rt13': 0.5125783937044045,\n",
       "  'p_htr': 0.4874216062950829,\n",
       "  'w_rt13': 1.0,\n",
       "  'w_htr': 0.0},\n",
       " {'file': 'RT13_13.png',\n",
       "  'label': 'rt13',\n",
       "  's_rt13': 0.9859190804301873,\n",
       "  's_htr': 0.9777284977960492,\n",
       "  's_max': 0.9859190804301873,\n",
       "  'margin': 0.008190582634138077,\n",
       "  'p_rt13': 0.5068250615856331,\n",
       "  'p_htr': 0.4931749384138599,\n",
       "  'w_rt13': 1.0,\n",
       "  'w_htr': 0.0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# STO RHEED classifier v2  (Blocks A, B, C implemented)\n",
    "# =========================\n",
    "\n",
    "import os, glob, json, math, csv, argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.optimize import nnls\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ---------------------------\n",
    "# Device & model (global)\n",
    "# ---------------------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def _init_resnet18():\n",
    "    resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    resnet.fc = nn.Identity()\n",
    "    resnet.to(DEVICE).eval()\n",
    "    return resnet\n",
    "\n",
    "RESNET = _init_resnet18()\n",
    "\n",
    "# Grayscale → 3ch + simple gray stats (domain-robust)\n",
    "TRANS_GRAY3 = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.Grayscale(num_output_channels=3),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities & preprocessing\n",
    "# ---------------------------\n",
    "def l2norm(x: np.ndarray, axis=1, eps=1e-12):\n",
    "    return x / (np.linalg.norm(x, axis=axis, keepdims=True) + eps)\n",
    "\n",
    "def list_images(folder: Optional[str]) -> List[str]:\n",
    "    if not folder:\n",
    "        return []\n",
    "    exts = (\"*.png\", \"*.bmp\", \"*.jpg\", \"*.jpeg\", \"*.tif\", \"*.tiff\")\n",
    "    paths: List[str] = []\n",
    "    for e in exts:\n",
    "        paths += glob.glob(os.path.join(folder, e))\n",
    "    return sorted(paths)\n",
    "\n",
    "def imread_gray(path: str) -> np.ndarray:\n",
    "    return np.array(Image.open(path).convert('L'), dtype=np.float32)\n",
    "\n",
    "def apply_center_mask(gray: np.ndarray, frac: float = 0.60) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Mask out the central bright disk; keep annulus.\n",
    "    frac: fraction of the shorter side used as mask diameter.\n",
    "    \"\"\"\n",
    "    h, w = gray.shape\n",
    "    cy, cx = h / 2.0, w / 2.0\n",
    "    R = min(h, w) * frac * 0.5  # radius\n",
    "    yy, xx = np.ogrid[:h, :w]\n",
    "    mask = ((yy - cy) ** 2 + (xx - cx) ** 2) > R ** 2\n",
    "    out = gray.copy()\n",
    "    out[~mask] = np.median(gray)\n",
    "    return out\n",
    "\n",
    "def _percentile_contrast(arr: np.ndarray) -> float:\n",
    "    p1, p99 = np.percentile(arr, [1, 99])\n",
    "    return float(p99 - p1)\n",
    "\n",
    "def _var_laplacian(arr: np.ndarray) -> float:\n",
    "    from scipy.ndimage import laplace\n",
    "    x = (arr - arr.min()) / max(1e-6, (arr.max() - arr.min()))\n",
    "    return float(laplace(x).var())\n",
    "\n",
    "def _sat_total(arr: np.ndarray, low=5, high=250) -> float:\n",
    "    n = arr.size\n",
    "    return float(((arr <= low).sum() + (arr >= high).sum()) / n)\n",
    "\n",
    "def score_quality(gray: np.ndarray) -> float:\n",
    "    \"\"\"Composite quality: high contrast & sharpness, low saturation.\"\"\"\n",
    "    c = _percentile_contrast(gray)\n",
    "    v = _var_laplacian(gray)\n",
    "    s = _sat_total(gray)\n",
    "    # normalize roughly by robust scales to balance terms\n",
    "    c_n = c / 255.0\n",
    "    v_n = v / (v + 1.0)\n",
    "    s_n = s  # already 0..1-ish fraction\n",
    "    return 0.4 * c_n + 0.5 * v_n + 0.1 * (1.0 - s_n)\n",
    "\n",
    "def fft_radial_profile(gray_224: np.ndarray, n_bins: int = 128) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalized radial power spectrum (1, n_bins).\n",
    "    gray_224 should already be 224x224 for consistency.\n",
    "    \"\"\"\n",
    "    g = (gray_224 - gray_224.mean()) / (gray_224.std() + 1e-6)\n",
    "    F = np.fft.fftshift(np.fft.fft2(g))\n",
    "    P = np.abs(F) ** 2\n",
    "    h, w = P.shape\n",
    "    cy, cx = h / 2.0, w / 2.0\n",
    "    yy, xx = np.indices(P.shape)\n",
    "    r = np.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)\n",
    "    r_norm = r / r.max()\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    idx = np.digitize(r_norm.ravel(), bins) - 1\n",
    "    prof = np.array([P.ravel()[idx == i].mean() if np.any(idx == i) else 0.0 for i in range(n_bins)])\n",
    "    prof = prof / (prof.max() + 1e-12)\n",
    "    return prof[None, :]\n",
    "\n",
    "def resnet_features_from_path(path: str) -> np.ndarray:\n",
    "    img = Image.open(path)\n",
    "    x = TRANS_GRAY3(img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        feat = RESNET(x)  # (1, D)\n",
    "    f = feat.cpu().numpy()\n",
    "    return l2norm(f, axis=1)\n",
    "\n",
    "\n",
    "# def extract_features(path: str,\n",
    "#                      mask_center: bool = True,\n",
    "#                      fft_bins: int = 128,\n",
    "#                      gamma_fft: float = 1.5) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Unified feature (Block C): [ResNet_embed || γ * FFT_radial_profile], L2-normalized.\n",
    "#     \"\"\"\n",
    "#     # CNN embed (grayscale→3ch)\n",
    "#     f_cnn = resnet_features_from_path(path)  # (1, D1)\n",
    "\n",
    "#     # FFT radial on masked grayscale resized to 224\n",
    "#     gray = imread_gray(path)\n",
    "#     if mask_center:\n",
    "#         gray = apply_center_mask(gray)\n",
    "#     gray224 = np.array(Image.fromarray(gray).resize((224, 224)))\n",
    "#     f_fft = fft_radial_profile(gray224, n_bins=fft_bins)  # (1, 128)\n",
    "\n",
    "#     f = np.concatenate([f_cnn, gamma_fft * f_fft], axis=1)\n",
    "#     return l2norm(f, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(path: str, mask_center: bool=True, fft_bins: int=128, gamma_fft: float=1.5):\n",
    "    # 1) load & preprocess once\n",
    "    gray = imread_gray(path)\n",
    "    if mask_center:\n",
    "        gray = apply_center_mask(gray)          # SAME mask for both branches\n",
    "    gray224 = np.array(Image.fromarray(gray).resize((224, 224)))\n",
    "\n",
    "    # 2) CNN on the preprocessed luminance (repeat-to-3ch inside TRANS_GRAY3)\n",
    "    img_for_cnn = Image.fromarray(gray224.astype(np.uint8))\n",
    "    x = TRANS_GRAY3(img_for_cnn).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        f_cnn = RESNET(x).cpu().numpy()\n",
    "    f_cnn = l2norm(f_cnn, axis=1)\n",
    "\n",
    "    # 3) FFT radial on the same gray224\n",
    "    f_fft = fft_radial_profile(gray224, n_bins=fft_bins)\n",
    "\n",
    "    # 4) concat + L2\n",
    "    f = np.concatenate([f_cnn, gamma_fft * f_fft], axis=1)\n",
    "    return l2norm(f, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Bank data classes\n",
    "# ---------------------------\n",
    "@dataclass\n",
    "class BankMeta:\n",
    "    fft_bins: int\n",
    "    mask_center: bool\n",
    "    feature_dim: int\n",
    "    tau_margin: float\n",
    "    kappa_minsim: float\n",
    "    temperature: float\n",
    "    gamma_fft: float\n",
    "    # multi-prototype storage\n",
    "    rt13_protos: List[np.ndarray]   # list of (D,)\n",
    "    htr_protos:  List[np.ndarray]   # list of (D,)\n",
    "    rt13_files: List[str]\n",
    "    htr_files:  List[str]\n",
    "\n",
    "@dataclass\n",
    "class PrototypeBank:\n",
    "    # For convenience we also keep mean prototypes (first entries), but we score via proto lists.\n",
    "    mu_rt13: np.ndarray     # (D,)\n",
    "    mu_htr:  np.ndarray     # (D,)\n",
    "    E_rt13:  np.ndarray     # (N_rt13, D)\n",
    "    E_htr:   np.ndarray     # (N_htr, D)\n",
    "    meta:    BankMeta\n",
    "\n",
    "    def save(self, out_npz: str):\n",
    "        os.makedirs(os.path.dirname(out_npz), exist_ok=True) if os.path.dirname(out_npz) else None\n",
    "        # Convert lists of arrays to a single array with object dtype for saving\n",
    "        rt13P = np.stack(self.meta.rt13_protos, axis=0) if len(self.meta.rt13_protos) else np.zeros((0, self.mu_rt13.shape[0]))\n",
    "        htrP  = np.stack(self.meta.htr_protos,  axis=0) if len(self.meta.htr_protos)  else np.zeros((0, self.mu_htr.shape[0]))\n",
    "        meta_dict = asdict(self.meta).copy()\n",
    "        # remove numpy arrays (we save separately)\n",
    "        meta_dict.pop('rt13_protos'); meta_dict.pop('htr_protos')\n",
    "        np.savez_compressed(\n",
    "            out_npz,\n",
    "            mu_rt13=self.mu_rt13,\n",
    "            mu_htr=self.mu_htr,\n",
    "            E_rt13=self.E_rt13,\n",
    "            E_htr=self.E_htr,\n",
    "            rt13_protos=rt13P,\n",
    "            htr_protos=htrP,\n",
    "            meta=json.dumps(meta_dict)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path_npz: str) -> \"PrototypeBank\":\n",
    "        z = np.load(path_npz, allow_pickle=True)\n",
    "        meta = json.loads(str(z[\"meta\"]))\n",
    "        rt13P = z[\"rt13_protos\"]; htrP = z[\"htr_protos\"]\n",
    "        meta_obj = BankMeta(\n",
    "            fft_bins=int(meta[\"fft_bins\"]),\n",
    "            mask_center=bool(meta[\"mask_center\"]),\n",
    "            feature_dim=int(meta[\"feature_dim\"]),\n",
    "            tau_margin=float(meta[\"tau_margin\"]),\n",
    "            kappa_minsim=float(meta[\"kappa_minsim\"]),\n",
    "            temperature=float(meta[\"temperature\"]),\n",
    "            gamma_fft=float(meta[\"gamma_fft\"]),\n",
    "            rt13_protos=[rt13P[i] for i in range(len(rt13P))],\n",
    "            htr_protos=[htrP[i] for i in range(len(htrP))],\n",
    "            rt13_files=list(meta[\"rt13_files\"]),\n",
    "            htr_files=list(meta[\"htr_files\"]),\n",
    "        )\n",
    "        return PrototypeBank(\n",
    "            mu_rt13=z[\"mu_rt13\"],\n",
    "            mu_htr=z[\"mu_htr\"],\n",
    "            E_rt13=z[\"E_rt13\"],\n",
    "            E_htr=z[\"E_htr\"],\n",
    "            meta=meta_obj\n",
    "        )\n",
    "\n",
    "# ---------------------------\n",
    "# Threshold tuning (Val or LOO)\n",
    "# ---------------------------\n",
    "def _grid_f1_tau_kappa(sim_pairs: List[Tuple[float, float, int]]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    sim_pairs: list of (s_rt13, s_htr, y_true) with y_true in {1 (rt13), 0 (htr)}.\n",
    "    Returns best (tau, kappa) by macro-F1, counting abstain as wrong.\n",
    "    \"\"\"\n",
    "    taus   = np.linspace(0.02, 0.15, 8)\n",
    "    kappas = np.linspace(0.15, 0.35, 9)\n",
    "    best_f1, best = -1.0, (0.08, 0.25)\n",
    "    y_true = [y for _, _, y in sim_pairs]\n",
    "    for t in taus:\n",
    "        for k in kappas:\n",
    "            y_pred = []\n",
    "            for sr, sh, _ in sim_pairs:\n",
    "                smax = max(sr, sh); margin = abs(sr - sh)\n",
    "                if smax < k or margin < t:\n",
    "                    y_pred.append(-1)  # abstain → treat as wrong for tuning\n",
    "                else:\n",
    "                    y_pred.append(1 if sr > sh else 0)\n",
    "            tp = sum((yt==1 and yp==1) for yt, yp in zip(y_true, y_pred))\n",
    "            tn = sum((yt==0 and yp==0) for yt, yp in zip(y_true, y_pred))\n",
    "            fp = sum((yt==0 and yp==1) for yt, yp in zip(y_true, y_pred))\n",
    "            fn = sum((yt==1 and yp==0) for yt, yp in zip(y_true, y_pred))\n",
    "            prec_pos = tp / max(1, tp+fp);  rec_pos = tp / max(1, tp+fn)\n",
    "            prec_neg = tn / max(1, tn+fn);  rec_neg = tn / max(1, tn+fp)\n",
    "            f1_pos = 2*prec_pos*rec_pos / max(1e-12, (prec_pos+rec_pos))\n",
    "            f1_neg = 2*prec_neg*rec_neg / max(1e-12, (prec_neg+rec_neg))\n",
    "            f1_macro = 0.5 * (f1_pos + f1_neg)\n",
    "            if f1_macro > best_f1:\n",
    "                best_f1, best = f1_macro, (t, k)\n",
    "    return best\n",
    "\n",
    "def _tune_thresholds_on_val(mu_rt13: np.ndarray, mu_htr: np.ndarray,\n",
    "                            val_rt13_paths: List[str], val_htr_paths: List[str],\n",
    "                            mask_center=True, fft_bins=128, gamma_fft=1.5) -> Optional[Tuple[float,float]]:\n",
    "    if not val_rt13_paths or not val_htr_paths:\n",
    "        return None\n",
    "    sims = []\n",
    "    for p in val_rt13_paths:\n",
    "        f = extract_features(p, mask_center=mask_center, fft_bins=fft_bins, gamma_fft=gamma_fft)\n",
    "        sr = float(cosine_similarity(f, mu_rt13[None, :])[0, 0])\n",
    "        sh = float(cosine_similarity(f, mu_htr [None, :])[0, 0])\n",
    "        sims.append((sr, sh, 1))\n",
    "    for p in val_htr_paths:\n",
    "        f = extract_features(p, mask_center=mask_center, fft_bins=fft_bins, gamma_fft=gamma_fft)\n",
    "        sr = float(cosine_similarity(f, mu_rt13[None, :])[0, 0])\n",
    "        sh = float(cosine_similarity(f, mu_htr [None, :])[0, 0])\n",
    "        sims.append((sr, sh, 0))\n",
    "    return _grid_f1_tau_kappa(sims)\n",
    "\n",
    "# ---------------------------\n",
    "# Build bank (Blocks B + C)\n",
    "# ---------------------------\n",
    "def _keep_topK_by_quality(paths: List[str], K: Optional[int]) -> List[str]:\n",
    "    if not K or K >= len(paths):\n",
    "        return paths\n",
    "    scored = []\n",
    "    for p in paths:\n",
    "        g = imread_gray(p)\n",
    "        scored.append((score_quality(g), p))\n",
    "    scored.sort(reverse=True, key=lambda t: t[0])\n",
    "    return [p for _, p in scored[:K]]\n",
    "\n",
    "def _compute_prototypes(E: np.ndarray, k_per_class: int) -> List[np.ndarray]:\n",
    "    \"\"\"Return list of k prototypes (means or k-means centroids), L2-normalized.\"\"\"\n",
    "    if k_per_class <= 1 or E.shape[0] < 3:\n",
    "        mu = l2norm(E.mean(axis=0, keepdims=True), axis=1)[0]\n",
    "        return [mu]\n",
    "    k = min(k_per_class, max(1, E.shape[0] // 2))  # avoid over-clustering\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=0)\n",
    "    km.fit(E)\n",
    "    protos = []\n",
    "    for ci in range(k):\n",
    "        members = E[km.labels_ == ci]\n",
    "        if len(members) == 0:\n",
    "            continue\n",
    "        mu = l2norm(members.mean(axis=0, keepdims=True), axis=1)[0]\n",
    "        protos.append(mu)\n",
    "    if not protos:\n",
    "        protos = [l2norm(E.mean(axis=0, keepdims=True), axis=1)[0]]\n",
    "    return protos\n",
    "\n",
    "def build_bank_from_dirs(rt13_dir: str,\n",
    "                         htr_dir: str,\n",
    "                         out_npz: Optional[str] = None,\n",
    "                         fft_bins: int = 128,\n",
    "                         mask_center: bool = True,\n",
    "                         gamma_fft: float = 1.5,         # Block C: FFT gain\n",
    "                         k_per_class: int = 2,           # Block B: multi-prototype\n",
    "                         top_k_rt13: Optional[int] = None,  # Block B: keep top-K by quality\n",
    "                         top_k_htr: Optional[int] = None,\n",
    "                         val_rt13_dir: Optional[str] = None,\n",
    "                         val_htr_dir: Optional[str] = None,\n",
    "                         temperature: float = 0.30       # Block A: sharper display probs\n",
    "                         ) -> PrototypeBank:\n",
    "    rt13_paths_all = list_images(rt13_dir)\n",
    "    htr_paths_all  = list_images(htr_dir)\n",
    "    if not rt13_paths_all or not htr_paths_all:\n",
    "        raise FileNotFoundError(\"No exemplar images found in provided exemplar folders.\")\n",
    "\n",
    "    # Block B: quality curation\n",
    "    rt13_paths = _keep_topK_by_quality(rt13_paths_all, top_k_rt13)\n",
    "    htr_paths  = _keep_topK_by_quality(htr_paths_all,  top_k_htr)\n",
    "\n",
    "    # Extract features\n",
    "    E_rt13 = np.vstack([extract_features(p, mask_center=mask_center, fft_bins=fft_bins, gamma_fft=gamma_fft)[0]\n",
    "                        for p in rt13_paths])\n",
    "    E_htr  = np.vstack([extract_features(p, mask_center=mask_center, fft_bins=fft_bins, gamma_fft=gamma_fft)[0]\n",
    "                        for p in htr_paths])\n",
    "\n",
    "    # Mean prototypes (also stored)\n",
    "    mu_rt13 = l2norm(E_rt13.mean(axis=0, keepdims=True), axis=1)[0]\n",
    "    mu_htr  = l2norm(E_htr.mean(axis=0,  keepdims=True), axis=1)[0]\n",
    "\n",
    "    # Block B: multi-prototype (k-means centroids, L2-normalized)\n",
    "    rt13_protos = _compute_prototypes(E_rt13, k_per_class=k_per_class)\n",
    "    htr_protos  = _compute_prototypes(E_htr,  k_per_class=k_per_class)\n",
    "\n",
    "    # thresholds: try Val first; fallback to LOO\n",
    "    tau, kappa = 0.08, 0.25\n",
    "    tuned = None\n",
    "    val_rt13_paths = list_images(val_rt13_dir)\n",
    "    val_htr_paths  = list_images(val_htr_dir)\n",
    "    if val_rt13_paths and val_htr_paths:\n",
    "        tuned = _tune_thresholds_on_val(mu_rt13, mu_htr, val_rt13_paths, val_htr_paths,\n",
    "                                        mask_center=mask_center, fft_bins=fft_bins, gamma_fft=gamma_fft)\n",
    "    if tuned is None:\n",
    "        # LOO on exemplars (still using mean prototypes for tuning simplicity)\n",
    "        sims = []\n",
    "        all_pairs = [(p, 1) for p in rt13_paths] + [(p, 0) for p in htr_paths]\n",
    "        for p, y in all_pairs:\n",
    "            f = extract_features(p, mask_center=mask_center, fft_bins=fft_bins, gamma_fft=gamma_fft)\n",
    "            sr = float(cosine_similarity(f, mu_rt13[None, :])[0, 0])\n",
    "            sh = float(cosine_similarity(f, mu_htr [None, :])[0, 0])\n",
    "            sims.append((sr, sh, y))\n",
    "        tau, kappa = _grid_f1_tau_kappa(sims)\n",
    "    else:\n",
    "        tau, kappa = tuned\n",
    "\n",
    "    meta = BankMeta(\n",
    "        fft_bins=fft_bins,\n",
    "        mask_center=mask_center,\n",
    "        feature_dim=int(len(mu_rt13)),\n",
    "        tau_margin=float(tau),\n",
    "        kappa_minsim=float(kappa),\n",
    "        temperature=float(temperature),\n",
    "        gamma_fft=float(gamma_fft),\n",
    "        rt13_protos=[p for p in rt13_protos],\n",
    "        htr_protos=[p for p in htr_protos],\n",
    "        rt13_files=rt13_paths,\n",
    "        htr_files=htr_paths,\n",
    "    )\n",
    "    bank = PrototypeBank(mu_rt13=mu_rt13, mu_htr=mu_htr, E_rt13=E_rt13, E_htr=E_htr, meta=meta)\n",
    "\n",
    "    if out_npz:\n",
    "        bank.save(out_npz)\n",
    "        print(f\"[OK] bank saved -> {out_npz}\")\n",
    "    print(f\"τ={meta.tau_margin:.3f}, κ={meta.kappa_minsim:.3f}, T={meta.temperature:.2f}, γ_fft={meta.gamma_fft:.2f}, k_per_class={k_per_class}\")\n",
    "    print(f\"rt13 exemplars used: {len(rt13_paths)} / {len(rt13_paths_all)}  |  htr exemplars used: {len(htr_paths)} / {len(htr_paths_all)}\")\n",
    "    return bank\n",
    "\n",
    "# ---------------------------\n",
    "# Prediction helpers (Block A override)\n",
    "# ---------------------------\n",
    "def softmax_scores(scores: np.ndarray, T: float = 1.0) -> np.ndarray:\n",
    "    z = (scores / max(1e-12, T))\n",
    "    z = z - z.max()\n",
    "    e = np.exp(z)\n",
    "    return e / (e.sum() + 1e-12)\n",
    "\n",
    "def mixture_weights_nnls(f: np.ndarray, protos: List[np.ndarray]) -> np.ndarray:\n",
    "    P = np.stack(protos, axis=1)  # (D, C)\n",
    "    w, _ = nnls(P, f)             # (C,)\n",
    "    s = w.sum()\n",
    "    return (w / s) if s > 1e-12 else np.ones_like(w)/len(w)\n",
    "\n",
    "def _class_score_maxproto(f: np.ndarray, protos: List[np.ndarray]) -> float:\n",
    "    \"\"\"Score = max cosine similarity to any prototype in the class.\"\"\"\n",
    "    if not protos:\n",
    "        return -1.0\n",
    "    Ps = np.stack(protos, axis=0)  # (k, D)\n",
    "    sims = (Ps @ f[0])  # because all are L2-normed, cosine = dot\n",
    "    return float(sims.max())\n",
    "\n",
    "def predict_one(image_path: str, bank: PrototypeBank) -> Dict:\n",
    "    f = extract_features(image_path,\n",
    "                         mask_center=bank.meta.mask_center,\n",
    "                         fft_bins=bank.meta.fft_bins,\n",
    "                         gamma_fft=bank.meta.gamma_fft)\n",
    "    # Block B: score vs multi-prototypes\n",
    "    s_rt13 = _class_score_maxproto(f, bank.meta.rt13_protos)\n",
    "    s_htr  = _class_score_maxproto(f,  bank.meta.htr_protos)\n",
    "    s_max  = max(s_rt13, s_htr)\n",
    "    margin = abs(s_rt13 - s_htr)\n",
    "\n",
    "    # display probabilities (softmax over similarities)\n",
    "    probs = softmax_scores(np.array([s_rt13, s_htr]), T=bank.meta.temperature)\n",
    "    p_rt13, p_htr = float(probs[0]), float(probs[1])\n",
    "\n",
    "    # NNLS mixture weights w.r.t. MEAN prototypes (stable 2D reconstruction)\n",
    "    w = mixture_weights_nnls(f[0], [bank.mu_rt13, bank.mu_htr])  # [w_rt13, w_htr]\n",
    "\n",
    "    # Block A: decision rule with NNLS override\n",
    "    # thresholds gate\n",
    "    if s_max < bank.meta.kappa_minsim:\n",
    "        label = \"uncertain\"\n",
    "    else:\n",
    "        if margin >= bank.meta.tau_margin:\n",
    "            label = \"rt13\" if s_rt13 > s_htr else \"htr\"\n",
    "        else:\n",
    "            # NNLS override if decisive\n",
    "            if (w[0] >= 0.60) and (w[0] - w[1] >= 0.20):\n",
    "                label = \"rt13\"\n",
    "            elif (w[1] >= 0.60) and (w[1] - w[0] >= 0.20):\n",
    "                label = \"htr\"\n",
    "            else:\n",
    "                label = \"uncertain\"\n",
    "\n",
    "    return {\n",
    "        \"file\": os.path.basename(image_path),\n",
    "        \"label\": label,\n",
    "        \"s_rt13\": s_rt13,\n",
    "        \"s_htr\":  s_htr,\n",
    "        \"s_max\":  s_max,\n",
    "        \"margin\": margin,\n",
    "        \"p_rt13\": p_rt13,\n",
    "        \"p_htr\":  p_htr,\n",
    "        \"w_rt13\": float(w[0]),\n",
    "        \"w_htr\":  float(w[1]),\n",
    "    }\n",
    "\n",
    "def predict_folder_with_bank(input_dir: str, bank: PrototypeBank, out_csv: Optional[str] = None) -> List[Dict]:\n",
    "    paths = list_images(input_dir)\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images found in '{input_dir}'\")\n",
    "    rows = [predict_one(p, bank) for p in paths]\n",
    "    if out_csv:\n",
    "        os.makedirs(os.path.dirname(out_csv), exist_ok=True) if os.path.dirname(out_csv) else None\n",
    "        with open(out_csv, \"w\", newline=\"\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "            w.writeheader()\n",
    "            for r in rows:\n",
    "                w.writerow(r)\n",
    "        print(f\"[OK] wrote {len(rows)} predictions -> {out_csv}\")\n",
    "    return rows\n",
    "\n",
    "\n",
    "\n",
    "bank = build_bank_from_dirs(\n",
    "    htr_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/STO_ideal_HTR\",\n",
    "    rt13_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/STO_ideal_RT13\",\n",
    "    out_npz=\"artifacts/banks/sto_bank_2025_10_21.npz\",\n",
    "    fft_bins=128,\n",
    "    mask_center=True,\n",
    "    gamma_fft=1.5,            # Block C\n",
    "    k_per_class=2,            # Block B multi-prototype\n",
    "    top_k_rt13=None,          # or an integer like 8 to keep only top-quality\n",
    "    top_k_htr=None,           # same idea\n",
    "    val_rt13_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/Val\",\n",
    "    val_htr_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/Val\",\n",
    "    temperature=0.30          # Block A: sharper display probs\n",
    ")\n",
    "\n",
    "rows = predict_folder_with_bank(\n",
    "    input_dir=\"/Users/justinmeng/Desktop/Project Quantum/data/Test\",\n",
    "    bank=bank,\n",
    "    out_csv=\"artifacts/results/test_preds.csv\"\n",
    ")\n",
    "rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
